{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6RxqIirisTj"
      },
      "source": [
        "To run this, press \"Runtime\" and press \"Run all\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Join our Discord if you need help!\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://github.com/unslothai/unsloth#installation-instructions---conda).\n",
        "\n",
        "You will learn how to do [DPO data prep](#Data), and how to [train via `DPOTrainer`](#Train).\n",
        "To learn more about DPO, read TRL's [blog post](https://huggingface.co/blog/dpo-trl). We follow [Huggingface's Alignment Handbook](https://github.com/huggingface/alignment-handbook) to replicate [Zephyr](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eSvM9zX_2d3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYds3fcii6gC"
      },
      "source": [
        "* We support Llama, Mistral, CodeLlama, TinyLlama, Vicuna, Open Hermes etc\n",
        "* And Yi, Qwen ([llamafied](https://huggingface.co/models?sort=trending&search=qwen+llama)), Deepseek, all Llama, Mistral derived archs.\n",
        "* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n",
        "* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n",
        "* With [PR 26037](https://github.com/huggingface/transformers/pull/26037), we support downloading 4bit models **4x faster**! [Our repo](https://huggingface.co/unsloth) has Llama, Mistral 4bit models.\n",
        "* DPO requires a model already trained by SFT on a similar dataset that is used for DPO. We use `HuggingFaceH4/mistral-7b-sft-beta` as the SFT model. Use this [notebook](https://colab.research.google.com/drive/1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_?usp=sharing) first to train a SFT model.\n",
        "* [**NEW**] We make Gemma 6 trillion tokens **2.5x faster**! See our [Gemma notebook](https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8-BWi7MzkRz",
        "outputId": "671c0a53-324f-42d7-b2ad-396c0b2a4835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "# One must patch the DPO Trainer first!\n",
        "from unsloth import PatchDPOTrainer\n",
        "PatchDPOTrainer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference from checkpoints"
      ],
      "metadata": {
        "id": "vDtZH5OLB2FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"qiqiquq/dpo-rpo-ranker-halfdata-1202-merged-16bit\", # Choose ANY! eg mistralai/Mistral-7B-Instruct-v0.2\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "dc4df984c5324c98803a999e20cc6249",
            "912a51aab4394936a708abf4acb2a1cd",
            "d46e920cb7004a77a455dbf92fd28e1c",
            "740617ef1ca34c61a374e986c50f061a",
            "af5e02dffb6b4104a85778f0b96ea214",
            "9f18aa3b75c142aa8a137b19030fbbbc",
            "c4ee6458afc840b0b5a2b2da50f8ea6e",
            "a88d170bee924807b7c1580f84a5a753",
            "f0738d3a355b4bf78dd3a5a8c5bd4c2b",
            "96c2fa5e465f498fa0604e02532a1492",
            "f2d53b7d93f24351a73e0549798a7a28"
          ]
        },
        "id": "G03dVsE6B_xG",
        "outputId": "f7f23c2b-6cd3-423f-f68c-feb8c57a84a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2024.11.10: Fast Mistral patching. Transformers:4.46.2.\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc4df984c5324c98803a999e20cc6249"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Will load qiqiquq/dpo-rpo-ranker-halfdata-1202-merged-16bit as a legacy tokenizer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Zero-shot Inference: Comment out the above cell and uncomment the following"
      ],
      "metadata": {
        "id": "iExf3Ef9E96C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "o_model, o_tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"mistralai/Mistral-7B-Instruct-v0.2\", # Choose ANY! eg mistralai/Mistral-7B-Instruct-v0.2\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ry1vmsUE5TM",
        "outputId": "81853a68-7b4a-40d2-c959-986e31284c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2024.11.10: Fast Mistral patching. Transformers:4.46.2.\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 8.0. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test it"
      ],
      "metadata": {
        "id": "ol5vEp0P5q3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Continue the fibonnaci sequence.\", # instruction\n",
        "        \"1, 1, 2, 3, 5, 8\", # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "\n",
        "\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=64,\n",
        "    use_cache=True,\n",
        "    return_dict_in_generate=True,\n",
        "    temperature = 0\n",
        ")\n",
        "new_tokens = outputs[0][:, inputs['input_ids'].shape[1]:]\n",
        "decoded_output = tokenizer.batch_decode(new_tokens, skip_special_tokens=True)\n",
        "decoded_output[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rhTYAbiQZQXU",
        "outputId": "900d05b0-a0ff-404c-fab8-ba513a1a277b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Fibonacci sequence continues as follows: 13, 21, 34, 55, 89, 144, ...\\n\\nSo, the next number in the sequence is 144.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_data = pd.read_csv('/content/natural_language_top10.csv') # REPLACE IT\n"
      ],
      "metadata": {
        "id": "R1OHuLv3CzN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.iloc[0:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "x4itA0ETC_om",
        "outputId": "2dee6994-b0c7-43f6-d808-1d10d1b5d7d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id                                            history  \\\n",
              "0        5  Movie 50: The Usual Suspects (Genres: Drama, C...   \n",
              "\n",
              "                                          candidates  \\\n",
              "0  Movie 32: Twelve Monkeys (Genres: Science Fict...   \n",
              "\n",
              "                                        ground_truth  \n",
              "0  Movie 32: Twelve Monkeys,Movie 509: The Piano,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e1b09e0-cf9b-48cc-80d2-6c544cfb1763\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>history</th>\n",
              "      <th>candidates</th>\n",
              "      <th>ground_truth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>Movie 50: The Usual Suspects (Genres: Drama, C...</td>\n",
              "      <td>Movie 32: Twelve Monkeys (Genres: Science Fict...</td>\n",
              "      <td>Movie 32: Twelve Monkeys,Movie 509: The Piano,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e1b09e0-cf9b-48cc-80d2-6c544cfb1763')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e1b09e0-cf9b-48cc-80d2-6c544cfb1763 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e1b09e0-cf9b-48cc-80d2-6c544cfb1763');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 5,\n        \"max\": 5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"history\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Movie 50: The Usual Suspects (Genres: Drama, Crime, Thriller; Language: en; Overview: Verbal Kint tells feds about mythic crime lord Keyser Soze.),Movie 176: Living in Oblivion (Genres: Drama, Comedy; Language: en; Overview: Film about indie filmmaking, set in one day on set.),Movie 515: The Remains of the Day (Genres: Drama, Romance; Language: en; Overview: Butler's decorum challenged by love and political tensions post-WWI.),Movie 562: Welcome to the Dollhouse (Genres: Comedy, Drama; Language: en; Overview: Seventh grader faces bullying and neglect in suburban family life.),Movie 1171: Bob Roberts (Genres: Comedy, Drama; Language: en; Overview: Mockumentary explores a Senate candidate's media manipulation through music.),Movie 1392: Citizen Ruth (Genres: Drama, Comedy; Language: en; Overview: \\\"Citizen Ruth\\\" satirizes media frenzy over one woman's pregnancy.),Movie 1732: The Big Lebowski (Genres: Comedy, Crime; Language: en; Overview: Slacker mistaken for millionaire, faces bizarre events involving chaos.),Movie 1759: Four Days in September (Genres: Action, Drama, Foreign, History, Thriller; Language: pt; Overview: Journalist kidnaps ambassador to free friend and political prisoners.),Movie 1897: High Art (Genres: Drama, Romance; Language: en; Overview: Intern and photographer exploit each other, falling in love.),Movie 3083: All About My Mother (Genres: Comedy, Drama; Language: es; Overview: Mother mourns son\\u2019s tragic death, informs distant father in Barcelona.)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidates\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Movie 32: Twelve Monkeys (Genres: Science Fiction, Thriller, Mystery; Language: en; Overview: James Cole time travels to uncover a deadly virus's origin.),Movie 509: The Piano (Genres: Drama, Romance; Language: en; Overview: Mute pianist Ada McGrath navigates love and conflict in New Zealand.),Movie 714: Dead Man (Genres: Drama, Fantasy, Western; Language: en; Overview: Accountant William Blake, on the run, meets spiritual guide Nobody.),Movie 1439: Meet Wally Sparks (Genres: Comedy; Language: en; Overview: Wally Sparks investigates governor's mansion for scandal to boost ratings.),Movie 1715: Office Killer (Genres: Comedy, Horror, Thriller; Language: en; Overview: Lonely proofreader creates macabre basement office after accidental murder.),Movie 1921: Pi (Genres: Mystery, Drama, Thriller; Language: en; Overview: Mathematical genius discovers number-reality link, believes he can predict future.),Movie 2311: 2010 (Genres: Thriller, Science Fiction; Language: en; Overview: Americans and Russians unite to investigate Jupiter's black monolith.),Movie 3605: King Creole (Genres: Drama, Action, Music, Romance; Language: en; Overview: Danny Fisher, aspiring performer, faces crime boss's persistent pressure.),Movie 3852: The Tao of Steve (Genres: Comedy, Romance; Language: en; Overview: Underachieving teacher Dex reevaluates seduction after meeting a woman.)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Movie 32: Twelve Monkeys,Movie 509: The Piano,Movie 714: Dead Man,Movie 908: North by Northwest,Movie 1175: Delicatessen,Movie 1250: The Bridge on the River Kwai,Movie 1535: Love! Valour! Compassion!,Movie 1635: The Ice Storm,Movie 1715: Office Killer,Movie 1921: Pi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def generate_prompt(history, candidates, len_candidates):\n",
        "    return f\"\"\"You are a recommender system. Based on a user's historical likes and dislikes, rank the given candidate movies by their likelihood of being the user's next favorite, according to their watching history. Please think step by step.\n",
        "You MUST ONLY output the Rank of Movie id, do not include other information like genres and overview.\n",
        "This user's historical interactions: {history}\n",
        "There are {len_candidates} Candidates for recommendation: {candidates}\n",
        "\n",
        "Strictly follow the output format:\n",
        "Rank1: Movie id - Reason: shortly explain why the user would most likely enjoy this movie\n",
        "Rank2: Movie id - Reason: shortly explain why the user would likely enjoy this movie second\n",
        "...\n",
        "Rank{len_candidates}: Movie id - Reason: (shorter than 10 words) explain why this movie would be the least one the user would enjoy\n",
        "\n",
        "For example,\n",
        "Rank1: Movie 32 - Reason: because user like this topic (shorter than 10 words)\n",
        "...\n",
        "\n",
        "Please provide a ranked list of the recommended movies. You MUST rank only the given candidates and cannot include any movies not listed in the candidate list.\n",
        "Now, begin with 'Rank1:', Output:\"\"\"\n",
        "\n",
        "def parse_movie_list(movie_string):\n",
        "    \"\"\"\n",
        "    Parses a string of movies into a list of movie descriptions.\n",
        "    \"\"\"\n",
        "    # Split by \"Movie\" to separate each movie entry\n",
        "    movies = re.split(r'Movie (\\d+):', movie_string)\n",
        "    parsed_movies = []\n",
        "    parsed_movies_id = []\n",
        "\n",
        "    # Process the split results to extract movie details\n",
        "    for i in range(1, len(movies), 2):  # Skip the first split as it's before \"Movie\"\n",
        "        movie_id = movies[i].strip()  # Extract movie ID\n",
        "        movie_details = movies[i + 1].strip()  # Extract details\n",
        "        if movie_details.endswith(','):\n",
        "            movie_details = movie_details[:-1]\n",
        "        parsed_movies.append(f\"Movie {movie_id}:{movie_details}\")\n",
        "        parsed_movies_id.append(movie_id)\n",
        "    return parsed_movies, parsed_movies_id"
      ],
      "metadata": {
        "id": "XjThidn5DJXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FastLanguageModel.for_inference(model)\n",
        "FastLanguageModel.for_inference(o_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh4QGOoBG1nY",
        "outputId": "fdc51a89-0b29-40cf-e18a-e4254e3bd63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MistralForCausalLM(\n",
              "  (model): MistralModel(\n",
              "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x MistralDecoderLayer(\n",
              "        (self_attn): MistralAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): LlamaRotaryEmbedding()\n",
              "        )\n",
              "        (mlp): MistralMLP(\n",
              "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "    )\n",
              "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "def process_dataframe_rows_with_batch(df, model, tokenizer, output_file = 'output.csv', batch_size=8):\n",
        "    if 'result' not in df.columns:\n",
        "        df['result'] = None\n",
        "\n",
        "    batch_history = []\n",
        "    batch_candidates = []\n",
        "    batch_len_candidates = []\n",
        "    batch_idx = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        history, history_id = parse_movie_list(row['history'])\n",
        "        candidates, candidates_id = parse_movie_list(row['candidates'])\n",
        "        ground_truth, ground_truth_id = parse_movie_list(row['ground_truth'])\n",
        "        prompt_candidates = candidates[:]\n",
        "        random.shuffle(prompt_candidates)\n",
        "\n",
        "        user_history_desc = \" \".join(history)\n",
        "        cand = \", \".join(prompt_candidates)\n",
        "        len_cand = len(prompt_candidates)\n",
        "\n",
        "        batch_history.append(user_history_desc)\n",
        "        batch_candidates.append(cand)\n",
        "        batch_len_candidates.append(len_cand)\n",
        "        batch_idx.append(idx)\n",
        "\n",
        "        # If the batch is full, process it\n",
        "        if len(batch_history) == batch_size or idx == len(df) - 1:\n",
        "            prompts = [\n",
        "                generate_prompt(hist, cand, len_cand)\n",
        "                for hist, cand, len_cand in zip(batch_history, batch_candidates, batch_len_candidates)\n",
        "            ]\n",
        "\n",
        "            # Tokenize the batch\n",
        "            inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n",
        "\n",
        "            # Generate predictions for the batch\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=512,\n",
        "                use_cache=True,\n",
        "                return_dict_in_generate=True,\n",
        "                temperature=0\n",
        "            )\n",
        "\n",
        "            # Decode the output\n",
        "            new_tokens = outputs.sequences[:, inputs['input_ids'].shape[1]:]\n",
        "            decoded_outputs = tokenizer.batch_decode(new_tokens, skip_special_tokens=True)\n",
        "\n",
        "            # Write results back to the dataframe\n",
        "            for idx_in_batch, result in zip(batch_idx, decoded_outputs):\n",
        "                df.at[idx_in_batch, 'result'] = result\n",
        "\n",
        "            # Clear the batch\n",
        "            batch_history = []\n",
        "            batch_candidates = []\n",
        "            batch_len_candidates = []\n",
        "            batch_idx = []\n",
        "\n",
        "        if idx % 10 == 0:\n",
        "            print(f\"Processed {idx} rows.\")\n",
        "            df.to_csv(output_file, index=False)\n",
        "\n",
        "    df.to_csv(output_file, index=False)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "FxvPLPMTDMLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_trained = 'output_t.csv'\n",
        "OUTPUT_original = 'otuput_o.csv'\n",
        "begin = 300\n",
        "inference_sample = 100\n",
        "# res_1 = process_dataframe_rows_with_batch(test_data[begin:begin+inference_sample], model, tokenizer,\n",
        "#                                         output_file = OUTPUT_trained,\n",
        "#                                         batch_size=28)\n",
        "res_2 = process_dataframe_rows_with_batch(test_data[begin:begin+inference_sample], o_model, o_tokenizer,\n",
        "                                        output_file = OUTPUT_original,\n",
        "                                        batch_size=28)\n",
        "# Ê†πÊçÆGPU‰ΩøÁî®ÁéáË∞ÉÊï¥batch sizeÔºõÊ†πÊçÆÈ¢ÑËÆ°ÊâßË°åÊó∂Èó¥Êó∂Èó¥Ë∞ÉÊï¥inferenceÁöÑÊï∞Èáè"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf7hkbIZETt3",
        "outputId": "71322669-fcb4-45ba-d223-aa595152d02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-71e71b736b11>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['result'] = None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 300 rows.\n",
            "Processed 310 rows.\n",
            "Processed 320 rows.\n",
            "Processed 330 rows.\n",
            "Processed 340 rows.\n",
            "Processed 350 rows.\n",
            "Processed 360 rows.\n",
            "Processed 370 rows.\n",
            "Processed 380 rows.\n",
            "Processed 390 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the inference results"
      ],
      "metadata": {
        "id": "dGdQaFTeKTD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_df_t = pd.read_csv(OUTPUT_trained).dropna()\n",
        "result_df_o = pd.read_csv(OUTPUT_original).dropna()"
      ],
      "metadata": {
        "id": "0Pwtx745L7vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_movie_gt(movie_string):\n",
        "    \"\"\"\n",
        "    Parses a string of movies into a list of movie descriptions.\n",
        "    \"\"\"\n",
        "    # Split by \"Movie\" to separate each movie entry\n",
        "    movies = re.split(r'Movie (\\d+):', movie_string)\n",
        "    parsed_movies = []\n",
        "\n",
        "    # Process the split results to extract movie details\n",
        "    for i in range(1, len(movies), 2):  # Skip the first split as it's before \"Movie\"\n",
        "        movie_id = movies[i].strip()  # Extract movie ID\n",
        "        parsed_movies.append(int(movie_id))\n",
        "    return parsed_movies\n",
        "\n",
        "def parse_result(res_str):\n",
        "    \"\"\"\n",
        "    Parses a string of movies into a list of movie descriptions.\n",
        "    \"\"\"\n",
        "    movie_ids = re.findall(r'Rank\\d+:\\s*Movie\\s*(\\d+)', res_str)\n",
        "    # movie_ids = re.findall(r'Rank \\d+:\\s*Movie\\s*(\\d+)', res_str) # Â¶ÇÊûú‰Ω†Âú®Áî®SFT‰πãÂêéÁöÑÊ®°ÂûãÔºåÁî®Ëøô‰∏ÄË°åÔºõ IF YOU ARE USING MODEL AFTER SFT, USE THIS !!!!!!\n",
        "\n",
        "    return [int(movie_id) for movie_id in movie_ids]\n"
      ],
      "metadata": {
        "id": "ngn1YnsSKhIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_df(result):\n",
        "  result['candidate_parsed'] = result['candidates'].apply(parse_movie_gt)\n",
        "  result['gt_parsed'] = result['ground_truth'].apply(parse_movie_gt)\n",
        "  result['result_parsed'] = result['result'].apply(parse_result)\n",
        "  return result"
      ],
      "metadata": {
        "id": "MY3oDjsllEyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df_t = process_df(result_df_t)\n",
        "result_df_o = process_df(result_df_o)"
      ],
      "metadata": {
        "id": "HrJNb4EYlf8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df_t[['candidate_parsed', 'gt_parsed','result_parsed']].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2EJiF5BAlNoa",
        "outputId": "0c6b1d90-e6ff-4556-caf0-08885752e28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    candidate_parsed  \\\n",
              "0  [1, 272, 1196, 1354, 1662, 1693, 1951, 2144, 2...   \n",
              "1  [1, 349, 1196, 1880, 2144, 2388, 2791, 2792, 3...   \n",
              "2  [1, 107, 1123, 1196, 1762, 1926, 2243, 2579, 2...   \n",
              "3  [500, 556, 1004, 1028, 1055, 2000, 2144, 2424,...   \n",
              "4  [1, 176, 193, 1028, 1196, 1707, 2000, 3129, 31...   \n",
              "\n",
              "                                           gt_parsed  \\\n",
              "0  [1, 1028, 1196, 2000, 2144, 2424, 2581, 2791, ...   \n",
              "1  [1, 1028, 1196, 2000, 2144, 2424, 2581, 2791, ...   \n",
              "2  [1, 1028, 1196, 2000, 2144, 2424, 2581, 2791, ...   \n",
              "3  [1, 1028, 1196, 2000, 2144, 2424, 2581, 2791, ...   \n",
              "4  [1, 1028, 1196, 2000, 2144, 2424, 2581, 2791, ...   \n",
              "\n",
              "                                       result_parsed  \n",
              "0  [1693, 1, 2424, 1196, 1662, 1354, 1951, 3836, ...  \n",
              "1  [1196, 1, 2144, 1880, 2388, 3868, 1, 3136, 279...  \n",
              "2  [1, 2243, 1148, 597, 1270, 1307, 2804, 107, 17...  \n",
              "3  [2424, 500, 1285, 11, 2145, 1278, 1835, 2396, ...  \n",
              "4  [1028, 1, 1707, 176, 1079, 2406, 1, 3147, 1196...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-059a080f-6790-4041-b172-04cf20a3f210\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>candidate_parsed</th>\n",
              "      <th>gt_parsed</th>\n",
              "      <th>result_parsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 272, 1196, 1354, 1662, 1693, 1951, 2144, 2...</td>\n",
              "      <td>[1, 1028, 1196, 2000, 2144, 2424, 2581, 2791, ...</td>\n",
              "      <td>[1693, 1, 2424, 1196, 1662, 1354, 1951, 3836, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 349, 1196, 1880, 2144, 2388, 2791, 2792, 3...</td>\n",
              "      <td>[1, 1028, 1196, 2000, 2144, 2424, 2581, 2791, ...</td>\n",
              "      <td>[1196, 1, 2144, 1880, 2388, 3868, 1, 3136, 279...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 107, 1123, 1196, 1762, 1926, 2243, 2579, 2...</td>\n",
              "      <td>[1, 1028, 1196, 2000, 2144, 2424, 2581, 2791, ...</td>\n",
              "      <td>[1, 2243, 1148, 597, 1270, 1307, 2804, 107, 17...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[500, 556, 1004, 1028, 1055, 2000, 2144, 2424,...</td>\n",
              "      <td>[1, 1028, 1196, 2000, 2144, 2424, 2581, 2791, ...</td>\n",
              "      <td>[2424, 500, 1285, 11, 2145, 1278, 1835, 2396, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 176, 193, 1028, 1196, 1707, 2000, 3129, 31...</td>\n",
              "      <td>[1, 1028, 1196, 2000, 2144, 2424, 2581, 2791, ...</td>\n",
              "      <td>[1028, 1, 1707, 176, 1079, 2406, 1, 3147, 1196...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-059a080f-6790-4041-b172-04cf20a3f210')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-059a080f-6790-4041-b172-04cf20a3f210 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-059a080f-6790-4041-b172-04cf20a3f210');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c6a2180c-8a78-4c3b-bb0c-e8e7d1c82afe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6a2180c-8a78-4c3b-bb0c-e8e7d1c82afe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c6a2180c-8a78-4c3b-bb0c-e8e7d1c82afe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"result_df_t[['candidate_parsed', 'gt_parsed','result_parsed']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"candidate_parsed\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gt_parsed\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"result_parsed\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import List\n",
        "\n",
        "def calculate_metrics(gt_list: List[int], pred_list: List[int], k: int = 10) -> dict:\n",
        "    pred_list = pred_list[:k]\n",
        "    gt_set = set(gt_list)\n",
        "\n",
        "    hits = sum(1 for item in pred_list if item in gt_set)\n",
        "    hit_ratio = 1 if hits > 0 else 0\n",
        "\n",
        "    precision = hits / k if k > 0 else 0\n",
        "    recall = hits / len(gt_set) if gt_set else 0\n",
        "\n",
        "    dcg = 0\n",
        "    idcg = 0\n",
        "    for i, item in enumerate(pred_list):\n",
        "        if item in gt_set:\n",
        "            dcg += 1 / np.log2(i + 2)\n",
        "\n",
        "    for i in range(min(len(gt_set), k)):\n",
        "        idcg += 1 / np.log2(i + 2)\n",
        "\n",
        "    ndcg = dcg / idcg if idcg > 0 else 0\n",
        "\n",
        "    return hit_ratio, precision, recall, ndcg\n",
        "\n",
        "def add_metrics_to_df(df, k=10, comp_col = 'result_parsed'):\n",
        "    df['hit_ratio'] = 0.0\n",
        "    df['precision'] = 0.0\n",
        "    df['recall'] = 0.0\n",
        "    df['ndcg'] = 0.0\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        hit_ratio, precision, recall, ndcg = calculate_metrics(\n",
        "            row['gt_parsed'],\n",
        "            row[comp_col],\n",
        "            k = k\n",
        "        )\n",
        "\n",
        "        df.at[idx, 'hit_ratio'] = hit_ratio\n",
        "        df.at[idx, 'precision'] = precision\n",
        "        df.at[idx, 'recall'] = recall\n",
        "        df.at[idx, 'ndcg'] = ndcg\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "utP1OQH6KSYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Non-ranker')\n",
        "for k in [3, 5, 10]:\n",
        "  result_df_t = add_metrics_to_df(result_df_t,k=k, comp_col = 'candidate_parsed')\n",
        "  print('-'*20)\n",
        "  print(f\"For k = {k}\")\n",
        "\n",
        "  print(f\"Average Hit Ratio: {result_df_t['hit_ratio'].mean():.4f}\")\n",
        "  print(f\"Average Precision: {result_df_t['precision'].mean():.4f}\")\n",
        "  print(f\"Average Recall: {result_df_t['recall'].mean():.4f}\")\n",
        "  print(f\"Average NDCG: {result_df_t['ndcg'].mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x09AJ13xg0Wr",
        "outputId": "989f81f5-13dc-4737-aced-3d1b9068bbc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-ranker\n",
            "--------------------\n",
            "For k = 3\n",
            "Average Hit Ratio: 0.7381\n",
            "Average Precision: 0.3373\n",
            "Average Recall: 0.1012\n",
            "Average NDCG: 0.3679\n",
            "--------------------\n",
            "For k = 5\n",
            "Average Hit Ratio: 0.9048\n",
            "Average Precision: 0.3429\n",
            "Average Recall: 0.1714\n",
            "Average NDCG: 0.3637\n",
            "--------------------\n",
            "For k = 10\n",
            "Average Hit Ratio: 1.0000\n",
            "Average Precision: 0.3298\n",
            "Average Recall: 0.3298\n",
            "Average NDCG: 0.3468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Trained Ranker')\n",
        "for k in [3, 5, 10]:\n",
        "  result_df_t = add_metrics_to_df(result_df_t,k=k)\n",
        "  print('-'*20)\n",
        "  print(f\"For k = {k}\")\n",
        "\n",
        "  print(f\"Average Hit Ratio: {result_df_t['hit_ratio'].mean():.4f}\")\n",
        "  print(f\"Average Precision: {result_df_t['precision'].mean():.4f}\")\n",
        "  print(f\"Average Recall: {result_df_t['recall'].mean():.4f}\")\n",
        "  print(f\"Average NDCG: {result_df_t['ndcg'].mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2Z-d5V_go5X",
        "outputId": "7c1b3eed-1567-47da-9b8f-cb3a6e34d100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained Ranker\n",
            "--------------------\n",
            "For k = 3\n",
            "Average Hit Ratio: 0.9167\n",
            "Average Precision: 0.4802\n",
            "Average Recall: 0.1440\n",
            "Average NDCG: 0.5287\n",
            "--------------------\n",
            "For k = 5\n",
            "Average Hit Ratio: 0.9524\n",
            "Average Precision: 0.3786\n",
            "Average Recall: 0.1893\n",
            "Average NDCG: 0.4457\n",
            "--------------------\n",
            "For k = 10\n",
            "Average Hit Ratio: 0.9762\n",
            "Average Precision: 0.2905\n",
            "Average Recall: 0.2905\n",
            "Average NDCG: 0.3606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Zero-shot Ranker')\n",
        "for k in [3, 5, 10]:\n",
        "  result_df_o = add_metrics_to_df(result_df_o,k=k)\n",
        "  print('-'*20)\n",
        "  print(f\"For k = {k}\")\n",
        "\n",
        "  print(f\"Average Hit Ratio: {result_df_o['hit_ratio'].mean():.4f}\")\n",
        "  print(f\"Average Precision: {result_df_o['precision'].mean():.4f}\")\n",
        "  print(f\"Average Recall: {result_df_o['recall'].mean():.4f}\")\n",
        "  print(f\"Average NDCG: {result_df_o['ndcg'].mean():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiImwuxulrgr",
        "outputId": "9f803c4f-0f7d-4cbc-c6cc-e1230c06ca68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-shot Ranker\n",
            "--------------------\n",
            "For k = 3\n",
            "Average Hit Ratio: 0.8571\n",
            "Average Precision: 0.4563\n",
            "Average Recall: 0.1369\n",
            "Average NDCG: 0.4832\n",
            "--------------------\n",
            "For k = 5\n",
            "Average Hit Ratio: 0.9286\n",
            "Average Precision: 0.3929\n",
            "Average Recall: 0.1964\n",
            "Average NDCG: 0.4314\n",
            "--------------------\n",
            "For k = 10\n",
            "Average Hit Ratio: 0.9762\n",
            "Average Precision: 0.2964\n",
            "Average Recall: 0.2964\n",
            "Average NDCG: 0.3503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt9CHJqO6p30"
      },
      "source": [
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/u54VK8m8tk) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Mistral 7b 2x faster [free Colab](https://colab.research.google.com/drive/1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_?usp=sharing)\n",
        "2. Llama 7b 2x faster [free Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)\n",
        "3. TinyLlama 4x faster full Alpaca 52K in 1 hour [free Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)\n",
        "4. CodeLlama 34b 2x faster [A100 on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)\n",
        "5. Mistral 7b [free Kaggle version](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook)\n",
        "6. We also did a [blog](https://huggingface.co/blog/unsloth-trl) with ü§ó HuggingFace, and we're in the TRL [docs](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth)!\n",
        "7. `ChatML` for ShareGPT datasets, [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing)\n",
        "8. Text completions like novel writing [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)\n",
        "9. Gemma 6 trillion tokens is 2.5x faster! [free Colab](https://colab.research.google.com/drive/10NbwlsRChbma1v55m8LAPYG15uQv6HLo?usp=sharing)\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc4df984c5324c98803a999e20cc6249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_912a51aab4394936a708abf4acb2a1cd",
              "IPY_MODEL_d46e920cb7004a77a455dbf92fd28e1c",
              "IPY_MODEL_740617ef1ca34c61a374e986c50f061a"
            ],
            "layout": "IPY_MODEL_af5e02dffb6b4104a85778f0b96ea214"
          }
        },
        "912a51aab4394936a708abf4acb2a1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f18aa3b75c142aa8a137b19030fbbbc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c4ee6458afc840b0b5a2b2da50f8ea6e",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "d46e920cb7004a77a455dbf92fd28e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a88d170bee924807b7c1580f84a5a753",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0738d3a355b4bf78dd3a5a8c5bd4c2b",
            "value": 3
          }
        },
        "740617ef1ca34c61a374e986c50f061a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c2fa5e465f498fa0604e02532a1492",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f2d53b7d93f24351a73e0549798a7a28",
            "value": "‚Äá3/3‚Äá[00:07&lt;00:00,‚Äá‚Äá2.34s/it]"
          }
        },
        "af5e02dffb6b4104a85778f0b96ea214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f18aa3b75c142aa8a137b19030fbbbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ee6458afc840b0b5a2b2da50f8ea6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a88d170bee924807b7c1580f84a5a753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0738d3a355b4bf78dd3a5a8c5bd4c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96c2fa5e465f498fa0604e02532a1492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d53b7d93f24351a73e0549798a7a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}